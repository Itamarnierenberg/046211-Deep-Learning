{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Imports\n",
    "First let's import all of the relevant packages. make sure you installed all of the necessary packages from the env.yaml file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import RandomCrop\n",
    "from torchvision.transforms import RandomApply\n",
    "from torchvision.transforms import RandomAffine\n",
    "from torchvision.transforms import RandomRotation\n",
    "from torchvision.transforms import Grayscale\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.transforms import RandomHorizontalFlip\n",
    "from torchvision.transforms import ColorJitter\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from HowDoIFeel import HowDoIFeel\n",
    "import torch.nn as nn\n",
    "from TrainModel import train_model\n",
    "import Config as cfg\n",
    "from tools import show_examples\n",
    "from tools import plot_confusion_matrix\n",
    "from tools import print_hyper_params\n",
    "import optuna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Device\n",
    "Now we determine on which device we will run (Supporting MPS and CPU)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = cfg.GPU_STR if torch.has_mps else \"cpu\"\n",
    "print(f\"[INFO] Current training device: {device}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Augmentations\n",
    "In this section we will define the augmentations that we use for the training and for the validation and test sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    Resize((cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH)),\n",
    "    Grayscale(num_output_channels=cfg.NUM_INPUT_CHANNELS),\n",
    "    RandomHorizontalFlip(),\n",
    "    RandomApply([transforms.RandomAffine(0, translate=(0.2, 0.2))], p=0.5),\n",
    "    ColorJitter(),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    Resize((cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH)),\n",
    "    Grayscale(num_output_channels=cfg.NUM_INPUT_CHANNELS),\n",
    "    ToTensor()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset\n",
    "\n",
    "Now it's time to load the data from the dataset folder, split it to validation, training and test sets, we will show how many examples are in each class and show examples of images from the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load all the images within the specified folder and apply different augmentation\n",
    "train_data = datasets.ImageFolder(cfg.TRAIN_DIRECTORY, transform=train_transform)\n",
    "test_data = datasets.ImageFolder(cfg.TEST_DIRECTORY, transform=test_transform)\n",
    "\n",
    "classes = train_data.classes\n",
    "print(f\"[INFO] Class labels: {classes}\")\n",
    "# use train samples to generate train/validation set\n",
    "num_train_samples = len(train_data)\n",
    "train_size = int(np.floor(num_train_samples * cfg.TRAIN_SIZE))\n",
    "val_size = int(np.ceil(num_train_samples * cfg.VAL_SIZE))\n",
    "\n",
    "print(f'[INFO] Number of Training Samples = {train_size}')\n",
    "print(f'[INFO] Number of Validation Samples = {val_size}')\n",
    "print(f'[INFO] Number of total Samples = {num_train_samples}')\n",
    "assert train_size + val_size == num_train_samples\n",
    "\n",
    "# randomly split the training dataset into train and validation set\n",
    "train_data, val_data = random_split(train_data, [train_size, val_size])\n",
    "\n",
    "# modify the data transform applied towards the validation set\n",
    "val_data.dataset.transforms = test_transform\n",
    "\n",
    "# get the labels within the training set\n",
    "train_classes = [label for _, label in train_data]\n",
    "\n",
    "# count each labels within each classes\n",
    "class_count_train = Counter(train_classes)\n",
    "print(f\"[INFO] Total sample: {class_count_train}\")\n",
    "print(f'[INFO] Train Data Summarize:')\n",
    "for label, num_samples in class_count_train.items():\n",
    "    print(f'[INFO] \\tEmotion: {cfg.CODE_TO_STR[label]}, Samples: {num_samples}')\n",
    "# A tools function to pretty print all of the hyper parameters from the Config file\n",
    "print_hyper_params()\n",
    "train_loader = DataLoader(train_data, batch_size=cfg.BATCH_SIZE)\n",
    "val_loader = DataLoader(val_data, batch_size=cfg.BATCH_SIZE)\n",
    "test_loader = DataLoader(test_data, batch_size=cfg.BATCH_SIZE)\n",
    "\n",
    "# Visualize a few images from the data\n",
    "show_examples(train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model\n",
    "Now we will define the model to be trained, it will be determined by the different available options from the config file, and it might use transfer learning if feature extract is enabled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "is_pre_trained = False if cfg.MODEL == cfg.PERSONAL_1 or cfg.MODEL == cfg.PERSONAL_2 or cfg.MODEL == cfg.PERSONAL_3 or cfg.MODEL == cfg.PERSONAL_VGG else True\n",
    "model = HowDoIFeel(is_pre_trained=is_pre_trained)\n",
    "model = model.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  fine-tuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model.parameters()\n",
    "if is_pre_trained:\n",
    "    print(params_to_update)\n",
    "    print(\"[INFO] Params to learn:\")\n",
    "    if cfg.FEATURE_EXTRACT:\n",
    "        params_to_update = []  # override the initial list definition above\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                params_to_update.append(param)\n",
    "                print(f\"[INFO] \\t{name}\")\n",
    "    else:\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f\"[INFO] \\t{name}\")\n",
    "else:\n",
    "    print('[INFO] Network Architecture:')\n",
    "    print(model)\n",
    "# Observe that all parameters are being optimized"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train\n",
    "Training the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if cfg.OPTIMIZER == 'SGD':\n",
    "    optimizer = torch.optim.SGD(params_to_update, lr=cfg.LR, momentum=cfg.MOMENTUM, nesterov=True, weight_decay=cfg.WEIGHT_DECAY)\n",
    "elif cfg.OPTIMIZER == 'Adam':\n",
    "    optimizer = torch.optim.Adam(params_to_update, lr=cfg.LR, weight_decay=cfg.WEIGHT_DECAY)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "data_loaders = {'train': train_loader, 'val': val_loader}\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if cfg.USE_OPTUNA:\n",
    "    sampler = optuna.samplers.TPESampler()\n",
    "    study = optuna.create_study(study_name=\"FER-2013\", direction=\"maximize\", sampler=sampler)\n",
    "    study.optimize(lambda trial: train_model(trial, data_loaders, criterion), n_trials=20, timeout=600)\n",
    "    pruned_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]\n",
    "    complete_trials = [t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"  Value: \", trial.value)\n",
    "    print(\" Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\" {}: {}\".format(key, value))\n",
    "    optuna.visualization.plot_param_importances(study)\n",
    "    exit(1)\n",
    "else:\n",
    "    model, _, history = train_model(model, data_loaders, criterion, optimizer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation\n",
    "Evaluating the model, plotting the lose and accuracy and plotting a confusion matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if device == cfg.GPU_STR:\n",
    "    model = model.to(cfg.CPU_STR)\n",
    "torch.save(model.state_dict(), f'{cfg.RESULTS_DIRECTORY}/{cfg.MODEL_FILE}')\n",
    "# plot the training loss and accuracy overtime\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(history['train_acc'], label='train_acc')\n",
    "plt.plot(history['val_acc'], label='val_acc')\n",
    "plt.plot(history['train_loss'], label='train_loss')\n",
    "plt.plot(history['val_loss'], label='val_loss')\n",
    "plt.ylabel('Loss/Accuracy')\n",
    "plt.xlabel(\"#No of Epochs\")\n",
    "plt.title('Training Loss and Accuracy on FER2013')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "plt.savefig(f'{cfg.RESULTS_DIRECTORY}/{cfg.PLOT_FILE}')\n",
    "\n",
    "# evaluate the model based on the test set\n",
    "model = model.to(device)\n",
    "with torch.set_grad_enabled(False):\n",
    "    # set the evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # initialize a list to keep track of our predictions\n",
    "    predictions = []\n",
    "\n",
    "    # iterate through the test set\n",
    "    for (data, _) in test_loader:\n",
    "        # move the data into the device used for testing\n",
    "        data = data.to(device)\n",
    "\n",
    "        # perform a forward pass and calculate the training loss\n",
    "        output = model(data)\n",
    "        output = output.argmax(axis=1).cpu().numpy()\n",
    "        predictions.extend(output)\n",
    "\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "actual = [label for _, label in test_data]\n",
    "print(classification_report(actual, predictions, target_names=test_data.classes))\n",
    "con_mat = confusion_matrix(actual, predictions)\n",
    "plot_confusion_matrix(con_mat, test_data.classes)\n",
    "test_acc = (predictions == np.array(actual)).sum() / len(predictions)\n",
    "print(f\"[INFO] Final Test Accuracy = {test_acc}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
